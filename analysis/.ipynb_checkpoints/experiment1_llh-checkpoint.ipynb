{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04d536ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation of the packages\n",
    "\n",
    "import numpy as np\n",
    "from graph_tool.all import *\n",
    "import random\n",
    "import graph_tool.topology as gt\n",
    "import graph_tool.clustering as gc\n",
    "import graph_tool.centrality as gcent\n",
    "import graph_tool.generation as gg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib\n",
    "import copy\n",
    "from matplotlib.lines import Line2D \n",
    "from collections import defaultdict\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "from collections import Counter\n",
    "import math\n",
    "import scipy.stats\n",
    "import collections\n",
    "\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from scipy.stats import norm \n",
    "from sklearn.neighbors import KernelDensity \n",
    "from sklearn.utils.fixes import parse_version \n",
    "\n",
    "from sklearn.svm import SVC # \"Support vector classifier\"\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from collections import Counter\n",
    "#from tabulate import tabulate\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from scipy.stats.stats import pearsonr \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4fe4ec",
   "metadata": {},
   "source": [
    "## A-Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "406de155",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "\n",
    "def delta(a,b):\n",
    "    \"\"\"\n",
    "    Return 1 if a and b are identical, else 0\n",
    "    \"\"\"\n",
    "    if a == b:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "##########################################################################################################\n",
    "\n",
    "def theta(x):\n",
    "    \"\"\"\n",
    "    Return 1 if x is positif, else 0\n",
    "    \"\"\"\n",
    "    if x<0:\n",
    "        return(0)\n",
    "    else:\n",
    "        return(1)\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\n",
    "def likelihood_only_SI(t,beta,rate,T_SI_node,T_SI_neighbors):\n",
    "    \"\"\"\n",
    "    Return the likelihood that node i is in state T[i,t] at time t if infected by the simple contagion\n",
    "    Input:\n",
    "    - t: the time\n",
    "    - beta: parameter of the simple contagion\n",
    "    - rate: rate of infection of the spontaneous adoption\n",
    "    - T_SI_node: trajectory of the node i\n",
    "    - T_SI_neighbors: trjectory of the nighbours of node i\n",
    "    \n",
    "    \"\"\"\n",
    "    prod = np.prod([(1-beta)**(T_SI_N[t-1]) for T_SI_N in T_SI_neighbors]) # it is pi(1-beta)\n",
    "                                                     \n",
    "    SI_no_exponent = (1-prod)\n",
    "    SI = SI_no_exponent**(T_SI_node[t]*(1-T_SI_node[t-1]))\n",
    "                                            \n",
    "    SS_no_exponent = prod\n",
    "    SS = SS_no_exponent**((1-T_SI_node[t])*(1-T_SI_node[t-1]))\n",
    "    \n",
    "    IS = 0 ** (T_SI_node[t-1]*(1-T_SI_node[t]))\n",
    "    \n",
    "    II = 1 ** (T_SI_node[t-1]*T_SI_node[t])\n",
    "    \n",
    "    return(SI*SS*IS*II)\n",
    "\n",
    "\n",
    "######################################################################################################\n",
    "\n",
    "def prod_likelihood_only_SI(x):\n",
    "    \"\"\"\n",
    "    multiplication over all the time steps of the likelihood that node i is in state T[i,t] at time t if infected by the simple contagion\n",
    "    Input:\n",
    "    x: one row of the dataset, countaining the information of infection of a node\n",
    "    \"\"\"\n",
    "    \n",
    "    T_SI_node = x['trajectory_node']\n",
    "    T_SI_neighbors = x['trajectory_neighbors']\n",
    "    number_time = len(T_SI_node)\n",
    "    prod = np.prod([likelihood_only_SI(t,beta,rate,T_SI_node,T_SI_neighbors) for t in range(1,number_time)])\n",
    "    return(prod)\n",
    "\n",
    "#######################################################################################################\n",
    "\n",
    "# give the likelihood that node i is in state T[i,t] at time t\n",
    "def likelihood_only_CP(t,phi,rate,T_CP_node,T_CP_neighbors):\n",
    "        \"\"\"\n",
    "    Return the likelihood that node i is in state T[i,t] at time t if infected by the complex contagion\n",
    "    Input:\n",
    "    - t: the time\n",
    "    - phi: parameter of the complex contagion\n",
    "    - rate: rate of infection of the spontaneous adoption\n",
    "    - T_SI_node: trajectory of the node i\n",
    "    - T_SI_neighbors: trjectory of the nighbours of node i\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    nber_neighbors = len(T_CP_neighbors)\n",
    "    \n",
    "    if (nber_neighbors != 0):\n",
    "        prop_infected_neighb = sum([T_CP_N[t-1] for T_CP_N in T_CP_neighbors])/nber_neighbors\n",
    "    else:\n",
    "        prop_infected_neighb = 0\n",
    "        \n",
    "    condition = theta(prop_infected_neighb - phi)\n",
    "    \n",
    "    SI_no_exponent = condition\n",
    "    SI = SI_no_exponent**(T_CP_node[t]*(1-T_CP_node[t-1]))\n",
    "                                            \n",
    "    SS_no_exponent = (1 - condition)\n",
    "    SS = SS_no_exponent**((1-T_CP_node[t])*(1-T_CP_node[t-1]))\n",
    "    \n",
    "    IS = 0 ** (T_CP_node[t-1]*(1-T_CP_node[t]))\n",
    "    \n",
    "    II = 1 ** (T_CP_node[t-1]*T_CP_node[t])\n",
    "    \n",
    "    return(SI*SS*IS*II)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "def prod_likelihood_only_CP(x):\n",
    "    \"\"\"\n",
    "    multiplication over all the time steps of the likelihood that node i is in state T[i,t] at time t if infected by the complex contagion\n",
    "    Input:\n",
    "    x: one row of the dataset, countaining the information of infection of a node\n",
    "    \"\"\"\n",
    "        \n",
    "    T_CP_node = x['trajectory_node']\n",
    "    T_CP_neighbors = x['trajectory_neighbors']\n",
    "    number_time = len(T_CP_node)\n",
    "    prod = np.prod([likelihood_only_CP(t,phi,rate,T_CP_node,T_CP_neighbors) for t in range(1,number_time)])\n",
    "    return(prod) \n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "def from_adjmatrix_to_adjlist(A):\n",
    "    \"\"\"\n",
    "    Function which takes in input the adjacency matrix and returns the adjacency list\n",
    "    \"\"\"\n",
    "    A = A.toarray()\n",
    "    adjList = defaultdict(list)\n",
    "    for i in range(np.shape(A)[0]):\n",
    "        for j in range(np.shape(A[i])[0]):\n",
    "            if A[i][j]== 1:\n",
    "                adjList[i].append(j)\n",
    "    return(adjList)\n",
    "\n",
    "###############################################################################################################\n",
    "\n",
    "def ratio(x):\n",
    "    \"\"\"\n",
    "    Adding a row in the dataset of the ratio likelihood of being complex / likelihood of being simple\n",
    "    \"\"\"\n",
    "    \n",
    "    num = x['llh_CP']\n",
    "    den = x['llh_SI']\n",
    "    \n",
    "    if (den != 0):\n",
    "        return(num/den)\n",
    "    else:\n",
    "        return(np.nan)\n",
    "    \n",
    "###############################################################################################################\n",
    "\n",
    "def guess(x):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returning the inferred classification, 0 for simple and 1 for complex\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    x_only_SI = x.llh_only_SI\n",
    "    \n",
    "    x_only_CP = x.llh_only_CP\n",
    "    \n",
    "    m = max([x_only_SI, x_only_CP])\n",
    "    \n",
    "    if ((m==x_only_SI) & (m!=x_only_CP)):\n",
    "        return(0)\n",
    "        \n",
    "    elif ((m==x_only_CP) & (m!=x_only_SI)):\n",
    "        return(1)\n",
    "        \n",
    "    else:\n",
    "        return ('not comparable')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466f4430",
   "metadata": {},
   "source": [
    "# B- getting the path of the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eabc55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dir_data = os.getcwd()[:-8]+'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1329b251",
   "metadata": {},
   "source": [
    "# C- making the classification on the whole dataset of Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "001f9df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'ER'\n",
    "list_beta = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "list_phi = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "sample_size = 10000 # 1000\n",
    "rate = 0.005\n",
    "name_cascade = 'general'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b567263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ER\n",
      "beta 0.1 phi 0.1\n",
      "beta 0.1 phi 0.3\n",
      "beta 0.1 phi 0.5\n",
      "beta 0.1 phi 0.7\n",
      "beta 0.1 phi 0.9\n",
      "beta 0.3 phi 0.1\n",
      "beta 0.3 phi 0.3\n",
      "beta 0.3 phi 0.5\n",
      "beta 0.3 phi 0.7\n",
      "beta 0.3 phi 0.9\n",
      "beta 0.5 phi 0.1\n",
      "beta 0.5 phi 0.3\n",
      "beta 0.5 phi 0.5\n",
      "beta 0.5 phi 0.7\n",
      "beta 0.5 phi 0.9\n",
      "beta 0.7 phi 0.1\n",
      "beta 0.7 phi 0.3\n",
      "beta 0.7 phi 0.5\n",
      "beta 0.7 phi 0.7\n",
      "beta 0.7 phi 0.9\n",
      "beta 0.9 phi 0.1\n",
      "beta 0.9 phi 0.3\n",
      "beta 0.9 phi 0.5\n",
      "beta 0.9 phi 0.7\n",
      "beta 0.9 phi 0.9\n"
     ]
    }
   ],
   "source": [
    "for index_beta, beta in enumerate(list_beta):\n",
    "    for index_phi, phi in enumerate(list_phi):\n",
    "\n",
    "        with open(x_dir_data+'/df_experiment1/df_0_'+str(beta)+'_star_without_sp.pickle', 'rb') as handle:\n",
    "            df_SI = pickle.load(handle)\n",
    "\n",
    "        with open(x_dir_data+'/df_experiment1/df_1_'+str(phi)+'_star_without_sp.pickle', 'rb') as handle:\n",
    "            df_CP = pickle.load(handle)\n",
    "\n",
    "        # bootstap, we select sample_size\n",
    "        df_sample_SI = df_SI.sample(n=int(sample_size), replace=True, axis=0) \n",
    "        df_sample_CP = df_CP.sample(n=int(sample_size), replace=True, axis=0)\n",
    "\n",
    "        # knowing it is SI, likelihood it is SI and CP\n",
    "        df_sample_SI['llh_only_SI'] = df_sample_SI.apply(prod_likelihood_only_SI, axis=1)\n",
    "        df_sample_SI['llh_only_CP'] = df_sample_SI.apply(prod_likelihood_only_CP, axis=1)\n",
    "\n",
    "        # knowing it is CP, likelihood it is SI and CP\n",
    "        df_sample_CP['llh_only_SI'] = df_sample_CP.apply(prod_likelihood_only_SI, axis=1)\n",
    "        df_sample_CP['llh_only_CP'] = df_sample_CP.apply(prod_likelihood_only_CP, axis=1)\n",
    "\n",
    "\n",
    "        df_sample_SI['guess'] = df_sample_SI.apply(guess, axis = 1)\n",
    "        df_sample_CP['guess'] = df_sample_CP.apply(guess, axis = 1)\n",
    "\n",
    "        # construction of the confusion matrix\n",
    "        confusion_matrix = np.zeros((2,2))\n",
    "\n",
    "        confusion_matrix[0, 0] = df_sample_SI['guess'][df_sample_SI['guess'] == 0].count()\n",
    "        confusion_matrix[1, 0] = df_sample_SI['guess'][df_sample_SI['guess'] == 1].count()\n",
    "\n",
    "        confusion_matrix[0, 1] = df_sample_CP['guess'][df_sample_CP['guess'] == 0].count()\n",
    "        confusion_matrix[1, 1] = df_sample_CP['guess'][df_sample_CP['guess'] == 1].count()\n",
    "\n",
    "        with open('_llh_experiment1_confusion_matrix_'+str(network)+'_star_without_sp_'+str(beta*10)+'_phi_'+str(phi*10)+'.pickle', 'wb') as handle:\n",
    "            pickle.dump(confusion_matrix, handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f227d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0daaaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
