{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "contemporary-notebook",
   "metadata": {},
   "source": [
    "# Conception data for Experiment 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation of the packages\n",
    "\n",
    "import numpy as np\n",
    "from graph_tool.all import *\n",
    "import random\n",
    "import graph_tool.topology as gt\n",
    "import graph_tool.clustering as gc\n",
    "import graph_tool.centrality as gcent\n",
    "import graph_tool.generation as gg\n",
    "import graph_tool.stats as gs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib\n",
    "import copy\n",
    "from matplotlib.lines import Line2D \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "from collections import Counter\n",
    "import math\n",
    "import scipy.stats\n",
    "import collections\n",
    "\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from scipy.stats import norm \n",
    "from sklearn.neighbors import KernelDensity \n",
    "from sklearn.utils.fixes import parse_version \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from scipy.stats.stats import pearsonr \n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "import networkx as nx\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c43fe32",
   "metadata": {},
   "source": [
    "## A - Useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16416f6",
   "metadata": {},
   "source": [
    "### 1-Function which creates a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f939957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_network(network,N,mean_degree):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function which computes a graph\n",
    "    \n",
    "    Parameters:\n",
    "    - network: type of network between 'BA', 'SBM', 'ER', 'WS', 'kregular', 'bimodal_distribution', 'lognormal', 'cm' and 'twitter' (twitter is not a synthetic network but is uploaded)\n",
    "    - N: number of nodes\n",
    "    - mean_degree: average degree\n",
    "    \n",
    "    Return:\n",
    "    - g: the network\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if network == 'BA':\n",
    "        E = mean_degree*N/2\n",
    "        m = E/(N-1)\n",
    "        m = round(m)\n",
    "        g = gg.price_network(N, m=m, c=None, gamma=1.5, directed=False, seed_graph=None)\n",
    "\n",
    "    elif network == 'SBM':\n",
    "        nber_group = 20\n",
    "        b = [[k]*int(N/nber_group) for k in range(nber_group)]\n",
    "        b = list(itertools.chain.from_iterable(b))\n",
    "        p_between_groups = 0.001\n",
    "        E = mean_degree*N/2\n",
    "        nber_intergroup = nber_group*(nber_group-1)/2\n",
    "        nber_edges_between_groups = p_between_groups*E*nber_intergroup\n",
    "        nber_edges_in_groups = E - nber_edges_between_groups\n",
    "        nber_edges_one_group = nber_edges_in_groups / nber_group\n",
    "        ers = np.ones((nber_group, nber_group))*p_between_groups*E + np.eye(nber_group)*(nber_edges_one_group*2 - p_between_groups*E)\n",
    "        g = gg.generate_sbm(b, ers)\n",
    "        gs.remove_parallel_edges(g)\n",
    "        gs.remove_self_loops(g)\n",
    "\n",
    "    elif network == 'ER':\n",
    "        E = mean_degree*N/2\n",
    "        p = E*2/N/(N-1)\n",
    "        g = random_graph(N, lambda: np.random.binomial(N, p, size=None), directed=False)\n",
    "        \n",
    "    elif network == 'WS':\n",
    "        # p proportion of edges to rewire\n",
    "        p = 0.05\n",
    "        g = gg.circular_graph(N, k=2)\n",
    "        E = mean_degree*N/2\n",
    "        list_edges = list(g.edges())\n",
    "        list_nodes = list(g.vertices())\n",
    "\n",
    "        # list of edges to rewire\n",
    "        deleted_edges = random.sample(list_edges,int(p*E))\n",
    "        \n",
    "        # rewiring\n",
    "        for e in deleted_edges:\n",
    "            g.remove_edge(e)\n",
    "            new_edge_nodes = random.sample(list_nodes,2)\n",
    "            g.add_edge(new_edge_nodes[0], new_edge_nodes[1]) \n",
    "        \n",
    "    elif network == 'kregular':\n",
    "        g = random_graph(N, lambda: mean_degree, directed=False)\n",
    "        \n",
    "    elif network == 'bimodal_distribution' :\n",
    "        mu = mean_degree\n",
    "        delta = 0.5\n",
    "        sigma = 0.5\n",
    "        w1 = mu + sigma*math.sqrt((1-delta)/delta)\n",
    "        w2 = mu - sigma*math.sqrt(delta/(1-delta))\n",
    "        \n",
    "        E1 = w1*N/2\n",
    "        p1 = E1*2/N/(N-1)\n",
    "\n",
    "        E2 = w2*N/2\n",
    "        p2 = E2*2/N/(N-1)\n",
    "        \n",
    "        def deg_sample():\n",
    "\n",
    "            if random.uniform(0, 1) > 0.5:\n",
    "                return np.random.binomial(N, p1, size=None)\n",
    "            else:\n",
    "                return np.random.binomial(N, p2, size=None)\n",
    "        \n",
    "        g = random_graph(N, deg_sample, directed = False)\n",
    "        \n",
    "    elif (network == 'lognormal'):\n",
    "\n",
    "        g = random_graph(N, lambda: np.random.lognormal(mean=mean_degree, sigma=1.0, size=None), directed=False)\n",
    "            \n",
    "    elif (network[:2] == 'cm'): # configuration model\n",
    "        \n",
    "        with open('/mnt/sdb1/elsa/ML_6/twitter_egonet/degreedistribution_'+network.split('_')[1]+'_oneweek.pickle', 'rb') as handle:\n",
    "            degree_distribution_oneweek = pickle.load(handle)\n",
    "            \n",
    "        if ((np.sum(degree_distribution_oneweek) % 2) != 0):\n",
    "            degree_distribution_oneweek[-1] = degree_distribution_oneweek[-1] + 1\n",
    "            \n",
    "        G_oneweek = nx.configuration_model([int(k) for k in degree_distribution_oneweek])\n",
    "        G_oneweek.remove_edges_from(nx.selfloop_edges(G_oneweek))\n",
    "        list_edges = list(set(list(G_oneweek.edges())))\n",
    "        g = Graph(directed=False)\n",
    "        for edge in list_edges:\n",
    "            node1=edge[0]\n",
    "            node2=edge[1]\n",
    "            g.add_edge(node1, node2)\n",
    "            \n",
    "    elif (network == 'twitter'):\n",
    "        \n",
    "        with open('g_twitter_mention.pickle', 'rb') as handle:\n",
    "            g = pickle.load(handle)\n",
    "            \n",
    "    else:\n",
    "        print('It is not a name of network')\n",
    "        \n",
    "    return(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea964d",
   "metadata": {},
   "source": [
    "### 2-Function to compute the propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2e8775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which takes as an input the network g and returns the network g after a CP propagation.\n",
    "# The output g has as nodes properties the different characteristics of their own contamination\n",
    "\n",
    "class Mixed_Propagation:\n",
    "    \n",
    "    \"\"\"\n",
    "    This class makes a synthetic propagation\n",
    "\n",
    "    Parameters:\n",
    "    - g: network \n",
    "    - seed: list of nodes which are the seeds\n",
    "    - L_beta: list of the values of beta used in this experiment\n",
    "    - L_phi: list of the values of beta used in this experiment\n",
    "    - rate: probability of getting infected through spontaneous adoption\n",
    "    - phi_distri\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,g,seed,L_beta,L_phi,rate = 0.005):\n",
    "\n",
    "        self.g = g\n",
    "        self.rate = rate\n",
    "\n",
    "        # definiton of the quantities\n",
    "        self.N = g.num_vertices() # number of nodes\n",
    "        E = g.num_edges() # number of edges\n",
    "        p = E*2/self.N/(self.N-1) # density\n",
    "\n",
    "        # initialization of the trajectory\n",
    "        self.T = np.zeros((self.N,1))\n",
    "\n",
    "        # node property: threshold\n",
    "        self.threshold = self.g.new_vp(\"double\")\n",
    "        self.g.vp.threshold = self.threshold\n",
    "        self.threshold.a = np.random.choice(L_phi, size = self.N, replace = True)\n",
    "\n",
    "        # node property: beta\n",
    "        self.beta = self.g.new_vp(\"double\")\n",
    "        self.g.vp.beta = self.beta\n",
    "        self.beta.a = np.random.choice(L_beta, size = self.N, replace = True)\n",
    "        # all the states are now null\n",
    "\n",
    "        # node property: type contagion\n",
    "        self.type_contagion = self.g.new_vp(\"double\")\n",
    "        self.g.vp.type_contagion = self.type_contagion\n",
    "        self.type_contagion.a =  np.random.choice([0,1], size = self.N, replace = True) \n",
    "             # all the number of infected neighbors are now nan\n",
    "\n",
    "        # node property: state\n",
    "        self.state = self.g.new_vp(\"int\")\n",
    "        self.g.vp.state = self.state\n",
    "        self.previous_state = [0 for i in range(self.N)]\n",
    "            # all the states are now null\n",
    "\n",
    "        # node property: time of infection\n",
    "        self.time_infection = self.g.new_vp(\"double\")\n",
    "        self.g.vp.time_infection = self.time_infection\n",
    "        self.time_infection.a = [np.nan for i in range(self.N)]\n",
    "            # all the time of infection are now nan\n",
    "\n",
    "        # role of the node: 0 for seed, 1 for vulnerable, 2 for the others\n",
    "        self.role = self.g.new_vp(\"int\")\n",
    "        self.g.vp.role = self.role\n",
    "        #print('ici',[1/v.out_degree()>=threshold[v] if v.out_degree()!=0 else True for v in g.vertices()])\n",
    "        self.condition_vulnerable = [1/v.out_degree()>=self.threshold[v] if v.out_degree()!=0 else True for v in self.g.vertices()]\n",
    "        self.role.a = np.where(self.condition_vulnerable,1,2)\n",
    "\n",
    "        # node property: nber stimuli\n",
    "        self.nber_stimuli = self.g.new_vp(\"double\")\n",
    "        self.g.vp.nber_stimuli = self.nber_stimuli\n",
    "        self.nber_stimuli.a = [np.nan for i in range(self.N)]\n",
    "            # all the number of stimuli are now nan\n",
    "\n",
    "        # node property: nber stimuli by neighbors\n",
    "        self.nber_stimuli_by_neighbor = self.g.new_vp(\"double\")\n",
    "        self.g.vp.nber_stimuli_by_neighbor = self.nber_stimuli_by_neighbor\n",
    "        self.nber_stimuli_by_neighbor.a = [np.nan for i in range(self.N)]\n",
    "             # all the number of infected neighbors are now nan\n",
    "\n",
    "        # node property: nber infected neighbors\n",
    "        self.nber_infected_neighbors = self.g.new_vp(\"double\")\n",
    "        self.g.vp.nber_infected_neighbors = self.nber_infected_neighbors\n",
    "        self.nber_infected_neighbors.a = [np.nan for i in range(self.N)]\n",
    "             # all the number of infected neighbors are now nan\n",
    "\n",
    "        # node property: prop infected neighbors\n",
    "        self.prop_infected_neighbors = self.g.new_vp(\"double\")\n",
    "        self.g.vp.prop_infected_neighbors = self.prop_infected_neighbors\n",
    "        self.prop_infected_neighbors.a = [np.nan for i in range(self.N)]\n",
    "             # all the number of infected neighbors are now nan \n",
    "            \n",
    "        # node property: is_seed\n",
    "        self.is_seed = self.g.new_vp(\"double\")\n",
    "        self.g.vp.is_seed = self.is_seed\n",
    "        self.is_seed.a = [np.nan for i in range(self.N)]\n",
    "             # all the number of infected neighbors are now nan\n",
    "\n",
    "        # characteristics infection neighbors\n",
    "        # time infection neighbor, number stimuli, number of other neighbors that are connected\n",
    "        self.charac_infected_neighbors = self.g.new_vp(\"object\")\n",
    "        self.g.vp.charac_infected_neighbors = self.charac_infected_neighbors\n",
    "             # all the number of infected neighbors are now nan\n",
    "\n",
    "        # node property: waiting time: list of the difference between the time of contamination of a node and\n",
    "        # the contamination of its neighbors\n",
    "        self.waiting_time = self.g.new_vp(\"object\")\n",
    "        self.g.vp.waiting_time = self.waiting_time\n",
    "             # all the number of infected neighbors are now nan\n",
    "\n",
    "        # node property: rank of infection\n",
    "        self.rank = self.g.new_vp(\"double\")\n",
    "        self.g.vp.rank = self.rank\n",
    "        self.rank.a = [np.nan for i in range(self.N)]\n",
    "            # all the number of stimuli are now nan\n",
    "        self.r = 0\n",
    "\n",
    "        # contamination of the seeds\n",
    "        self.state[seed] = 1\n",
    "        self.time_infection[seed] = 0\n",
    "        self.role[seed] = 0\n",
    "        self.nber_stimuli[seed] = 0\n",
    "        self.nber_stimuli_by_neighbor[seed] = 0\n",
    "        self.nber_infected_neighbors[seed] = 0\n",
    "        self.prop_infected_neighbors[seed] = 0\n",
    "        self.waiting_time[seed] = [0]\n",
    "        self.charac_infected_neighbors[seed] = []\n",
    "        self.is_seed[seed] = 1\n",
    "        self.T[int(seed),0] = 1\n",
    "        self.rank[seed] = self.r\n",
    "        self.r+=1\n",
    "\n",
    "        #graph_draw(g,vertex_text=g.vertex_index,vertex_fill_color=g.vertex_properties['state'])\n",
    "        \n",
    "    def run(self):\n",
    "        \n",
    "        # initialisation of the time\n",
    "        t = 1\n",
    "\n",
    "        while (list(self.state.a).count(1) <= self.N*0.9) :\n",
    "\n",
    "            self.previous_state = self.state.a.copy()\n",
    "            susceptible_nodes = [v for v in self.g.vertices() if self.state[v]==0]\n",
    "\n",
    "            for v in susceptible_nodes: # for every susceptible nodes, we look if the threshold is reached\n",
    "\n",
    "                if (random.random() <= self.rate):\n",
    "                    self.infect_node(v,t,2)\n",
    "                    \n",
    "                elif (self.type_contagion[v] == 0):\n",
    "                    beta_v = self.beta[v]\n",
    "\n",
    "                    infected_neighbors = [n for n in list(v.out_neighbors()) if self.previous_state[self.g.vertex_index[n]]==1]\n",
    "                    # infection neighbors of the infected node v\n",
    "                    for n in range(len(infected_neighbors)):\n",
    "                        # go through all the susceptible neighbors\n",
    "                        if random.random() <= beta_v:\n",
    "                            # with a probability beta, we infect the susceptible node\n",
    "                            self.infect_node(v,t,0)\n",
    "                            break\n",
    "\n",
    "                else:\n",
    "                    if len(list(v.out_neighbors()))!=0:\n",
    "                        prop_infected_neighbors_v = len([n for n in list(v.out_neighbors()) if self.previous_state[self.g.vertex_index[n]]==1])/len(list(v.out_neighbors()))\n",
    "                    else:\n",
    "                        prop_infected_neighbors_v = 0\n",
    "                    if (prop_infected_neighbors_v>=self.threshold[v]): # if it is reached, we infect it\n",
    "                        self.infect_node(v,t,0)\n",
    "\n",
    "            susceptible_nodes = [v for v in self.g.vertices() if self.state[v]==0]\n",
    "            \n",
    "            state_t = np.asarray(self.state.a).reshape((self.N,1))\n",
    "            self.T = np.concatenate((self.T, state_t), axis=1)\n",
    "            t+=1\n",
    "\n",
    "    def infect_node(self,v,t,spontaneous):\n",
    "        self.state[v] = 1\n",
    "        self.time_infection[v] = t\n",
    "        self.nber_stimuli[v] = np.sum([t-self.time_infection[m] for m in v.out_neighbors() if self.previous_state[self.g.vertex_index[m]]==1])\n",
    "        self.nber_infected_neighbors[v] = len([m for m in v.out_neighbors() if self.previous_state[self.g.vertex_index[m]]==1])                    \n",
    "        \n",
    "        if (v.out_degree() != 0) :\n",
    "            self.nber_stimuli_by_neighbor[v] = self.nber_stimuli[v] / v.out_degree() \n",
    "            self.prop_infected_neighbors[v] = self.nber_infected_neighbors[v]/v.out_degree()\n",
    "        else: \n",
    "            self.nber_stimuli_by_neighbor[v] = 0\n",
    "            self.prop_infected_neighbors[v] = 0\n",
    "                    \n",
    "        self.waiting_time[v] = [t-self.time_infection[m] for m in v.out_neighbors() if self.previous_state[self.g.vertex_index[m]]==1] \n",
    "        self.charac_infected_neighbors[v] = [[self.time_infection[m]-t,t-self.time_infection[m],-1,len(list(set.intersection(set(list(v.out_neighbors())),set(list(m.out_neighbors())))))] for m in v.out_neighbors() if self.previous_state[self.g.vertex_index[m]]==1]\n",
    "        self.charac_infected_neighbors[v] = sorted(self.charac_infected_neighbors[v], key=lambda x: x[0])\n",
    "        self.is_seed[v] = spontaneous\n",
    "        self.rank[v] = self.r\n",
    "        self.r+=1\n",
    "        \n",
    "def from_adjmatrix_to_adjlist(A):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function which takes as an input an adjacency matrix of a network and return an adjacency matrix\n",
    "    \n",
    "    \"\"\"\n",
    "    A = A.toarray()\n",
    "    adjList = defaultdict(list)\n",
    "    for i in range(np.shape(A)[0]):\n",
    "        for j in range(np.shape(A[i])[0]):\n",
    "            if A[i][j]== 1:\n",
    "                adjList[i].append(j)\n",
    "    return(adjList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa6412b",
   "metadata": {},
   "source": [
    "### 3-Function to make the data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ad8921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conception_data_base(network, mean_degree, N_network, N, L_beta, L_phi, rate):\n",
    "    \n",
    "    \"\"\"\n",
    "    This class makes a synthetic propagation\n",
    "\n",
    "    Parameters:\n",
    "    - network : type of network between 'BA', 'SBM', 'ER', 'WS', 'kregular', 'bimodal_distribution', 'lognormal', 'cm' and 'twitter'\n",
    "    - mean_degree: mean degree of the network\n",
    "    - N_network: number of different network in the sample\n",
    "    - N: number of nodes\n",
    "    - L_beta: list of the values of beta used in this experiment\n",
    "    - L_phi: list of the values of phi used in this experiment\n",
    "    - rate: probability of getting infected through spontaneous adoption\n",
    "\n",
    "    \"\"\"\n",
    "   \n",
    "    name_columns = ['degree',\n",
    "                    'clustering_coefficient',\n",
    "                    'nber_infected_neighbors',\n",
    "                    'prop_infected_neighbors',\n",
    "                    'charac_infected_neighbors',\n",
    "                    'is_seed',\n",
    "                    'beta',\n",
    "                    'phi',\n",
    "                    'contagion',\n",
    "                    'trajectory',\n",
    "                    'adjacency_list',\n",
    "                    'index_node',\n",
    "                    'rank']\n",
    "    \n",
    "    df_set = pd.DataFrame(columns = name_columns) \n",
    "\n",
    "    for it in range(N_network): # for a certain number of networks\n",
    "\n",
    "        \n",
    "        g = make_random_network(network,N,mean_degree)\n",
    "        \n",
    "        A = graph_tool.spectral.adjacency(g)\n",
    "        adj_list = from_adjmatrix_to_adjlist(A)\n",
    "        #print('adj_list', adj_list)\n",
    "            \n",
    "        for i in range(1): ######## 10 ###########\n",
    "\n",
    "            # propagations in the network\n",
    "            g_work = g.copy()\n",
    "            N = len(list(g_work.vertices())) # number of nodes\n",
    "            seed = random.choice(list(g.vertices())) # pick up a seed\n",
    "            \n",
    "            M=Mixed_Propagation(g,seed,L_beta,L_phi)\n",
    "            M.run()\n",
    "\n",
    "            # features on the structusre of the ego-network\n",
    "            degree = np.array(g.get_out_degrees(g.get_vertices()))\n",
    "            clustering_coefficient = np.array(list(gc.local_clustering(g, weight=None, prop=None, undirected=True)))\n",
    "\n",
    "            # features on the propagation in the ego-network\n",
    "            nber_infected_neighbors = M.nber_infected_neighbors.a\n",
    "            prop_infected_neighbors = M.prop_infected_neighbors.a\n",
    "\n",
    "            # features on every alters    \n",
    "            # list infected neighbors [[list of infected neighbors of node 0],[list of infected neighbors of node 1], ...]\n",
    "            charac_infected_neighbors = list(M.g.vp.charac_infected_neighbors)\n",
    "                \n",
    "            # is_seed\n",
    "            is_seed = M.is_seed.a\n",
    "            \n",
    "            # phi\n",
    "            phi_nodes = M.threshold.a\n",
    "            \n",
    "            # beta\n",
    "            beta_nodes = M.beta.a\n",
    "            \n",
    "            # type contagion\n",
    "            contagion = M.type_contagion.a\n",
    "                \n",
    "            # node index\n",
    "            index_node = list(g.vertex_index)\n",
    "                \n",
    "            # node index\n",
    "            rank = M.rank.a\n",
    "                \n",
    "            # node adjacency list\n",
    "            adj_list_node = [adj_list[i] for i in index_node]\n",
    "            \n",
    "            \n",
    "            array_one_propagation = np.array([[degree[k], clustering_coefficient[k], nber_infected_neighbors[k], prop_infected_neighbors[k], charac_infected_neighbors[k], is_seed[k], beta_nodes[k], phi_nodes[k], contagion[k], M.T, adj_list_node[k], index_node[k], rank[k]] for k in range(N)])\n",
    "\n",
    "            df_temp = pd.DataFrame(array_one_propagation, columns=name_columns)\n",
    "\n",
    "            df_set = pd.concat([df_set, df_temp], ignore_index=True)\n",
    "            \n",
    "            #array_one_propagation = np.array([[degree[k], clustering_coefficient[k], nber_infected_neighbors[k], prop_infected_neighbors[k], charac_infected_neighbors[k], is_seed[k], beta_nodes[k], phi_nodes[k], contagion[k], M.T, adj_list_node[k], index_node[k], rank[k]] for k in range(N)])\n",
    "                \n",
    "            #df_set = df_set.append(pd.DataFrame(array_one_propagation,columns = name_columns),ignore_index = True)\n",
    "                \n",
    "    return(df_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535cf96f",
   "metadata": {},
   "source": [
    "### 4-Function to process the data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2769366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_df(df_set):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function which pre-process the data\n",
    "    \n",
    "    Input: the row data\n",
    "    \n",
    "    Return: the process data\n",
    "    \"\"\"\n",
    "\n",
    "    df = df_set.copy()\n",
    "    \n",
    "    df.dropna(subset = [\"nber_infected_neighbors\"], inplace=True)\n",
    "    df.reset_index(inplace = True)\n",
    "    \n",
    "    # creation of the column 'total number of stimuli received'\n",
    "    df['sum_stimuli'] = df['charac_infected_neighbors'].apply(lambda x:sum([k[1] for k in x]))\n",
    "    \n",
    "    # creation of the column 'std on the number of received stimuli'\n",
    "    df['std_stimuli'] = df['charac_infected_neighbors'].apply(lambda x:np.std([k[1] for k in x]) if len(x)!=0 else 0)\n",
    "    # np.std of an empty list is NaN\n",
    "    \n",
    "    # creation of the column 'number of stimuli by degree'\n",
    "    df['nber_stimuli_by_neighbors'] = [i / j if j!=0 else 0 for i, j in zip(list(df['sum_stimuli']), list(df['degree']))]\n",
    "    \n",
    "    # creation of the column 'time since last infected neighbor get infected'\n",
    "    df['time_last_infected_neighbor'] = df['charac_infected_neighbors'].apply(lambda x:min([-k[0] for k in x]) if len(x)!=0 else 0)\n",
    "    \n",
    "    # creation of the column 'time since first infected neighbor get infected'\n",
    "    df['time_first_infected_neighbor'] = df['charac_infected_neighbors'].apply(lambda x:max([-k[0] for k in x]) if len(x)!=0 else 0)\n",
    "    \n",
    "    df['trajectory_node'] = [traj[index,:] for traj, index in zip(list(df['trajectory']), list(df['index_node']))]\n",
    "    \n",
    "    df['trajectory_neighbors'] = [[traj[index,:] for index in list_index] for traj, list_index in zip(list(df['trajectory']), list(df['adjacency_list']))]\n",
    "    \n",
    "    df['parameter'] = [df.iloc[k]['beta'] if df.iloc[k]['contagion'] == 0 else df.iloc[k]['phi'] for k in range(len(df))] \n",
    "    \n",
    "    # selection of the features we are interested in\n",
    "    df_final = df[[\"degree\",\"clustering_coefficient\",\"nber_infected_neighbors\",\"prop_infected_neighbors\",\"sum_stimuli\",\"std_stimuli\",\"nber_stimuli_by_neighbors\",\"time_last_infected_neighbor\",\"time_first_infected_neighbor\",'is_seed','parameter','contagion',\"trajectory_node\",\"trajectory_neighbors\", \"index_node\",\"rank\"]]\n",
    "    \n",
    "    return(df_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ce407",
   "metadata": {},
   "source": [
    "## B - Test of the codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524e4ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 0.005\n",
    "mean_degree = 4\n",
    "N_network = 20 # 20 \n",
    "N = 10\n",
    "L_beta = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "L_phi = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "network = 'ER'\n",
    "\n",
    "df_set = conception_data_base(network, mean_degree, N_network, N, L_beta, L_phi, rate)\n",
    "df = preprocessing_df(df_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dacc66d",
   "metadata": {},
   "source": [
    "## C - Make the whole data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946fb9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 0.005\n",
    "mean_degree = 4\n",
    "N_network = 20 # 20 \n",
    "N = 1000\n",
    "L_beta = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "L_phi = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "network = 'ER'\n",
    "\n",
    "df_set = conception_data_base(network, mean_degree, N_network, N, L_beta, L_phi, rate)\n",
    "df = preprocessing_df(df_set)\n",
    "    \n",
    "with open('df_experiment2_3/df_'+name_dataset+'_premix_different_parameter.pickle', 'wb') as handle:\n",
    "    pickle.dump(df, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28340567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end of the code :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
